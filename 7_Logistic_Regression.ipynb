{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7.Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODd0R/mZfflyWaKVk/sscj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reeda23/Deep-Learning-With-Pytorch/blob/main/7_Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "1) Desgin model (input, output size, forward pass) <br>\n",
        "2) Construct loss and optimizer <br>\n",
        "3) Training loop<br>\n",
        "> -forward pass: compute prediction and loss <br>\n",
        "  -backward pass: compute gradients <br>\n",
        "  -update weights\n",
        "\n"
      ],
      "metadata": {
        "id": "WUgLA5R5-goB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import libraries**"
      ],
      "metadata": {
        "id": "PIBA0MDyUHzY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pzBjKIhN-XOC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "## Train-Test Split\n"
      ],
      "metadata": {
        "id": "p1yY1wclT46O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#step 0: prepare data\n",
        "#binary classification problem where we can predict cancer based on the \n",
        "#ipout features\n",
        "bc = datasets.load_breast_cancer()\n",
        "X, y = bc.data, bc.target\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(n_samples, n_features)   #569 samples and 30 features\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
        "\n",
        "#random_state simply sets a seed to the random generator, \n",
        "#so that your train-test splits are always deterministic. \n",
        "#If you don't set a seed, it is different each time.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYHihxUBUDG8",
        "outputId": "beb4a783-c4a8-4d88-c0b7-587c67c1b414"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "569 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Standarization of Data\n",
        "Always recommended to scale features to have zero mean and unit variance when dealing with logistic regression."
      ],
      "metadata": {
        "id": "0S-tMtW-WZuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scale\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "#If we will use the fit method on our test data too, we will compute a new\n",
        "#mean and variance that is a new scale for each feature and will let our model \n",
        "#learn about our test data too. Thus, what we want to keep as a surprise is no longer \n",
        "#unknown to our model and we will not get a good estimate of how our model is performing \n",
        "#on the test (unseen) data which is the ultimate goal of building a model using machine \n",
        "#learning algorithm.\n",
        "\n",
        "\n",
        "X_train = torch.from_numpy(X_train.astype(np.float32)) #converting into float32 because orignially it is in double and it will create some errors later on \n",
        "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
        "y_train = torch.from_numpy(y_train.astype(np.float32)) #original shape torch.Size([455])\n",
        "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
        "\n",
        "#reshaping\n",
        "y_train = y_train.view(y_train.shape[0], 1) #convert row into column vector\n",
        "y_test = y_test.view(y_test.shape[0], 1)"
      ],
      "metadata": {
        "id": "aCaDqm_FWnw_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "**function** -- linear combination of weights and bias <br>\n",
        "f = wx + b <br>\n",
        "sigmoid at the end"
      ],
      "metadata": {
        "id": "Nqz99SCNbqKn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1) model\n",
        "class LogisticRegression(nn.Module): #this class is derived from nn.Module\n",
        "\n",
        "    def __init__(self, n_input_features):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "\n",
        "        #define layers\n",
        "        #only one layer so use built-in layer\n",
        "        #30 input features and 1 output\n",
        "        self.linear = nn.Linear(n_input_features,1) #output size is 1 we only want 1 value at the end 0 or 1\n",
        " \n",
        "    #forward pass\n",
        "    def forward(self, x):\n",
        "        y_predicted = torch.sigmoid(self.linear(x))\n",
        "        return y_predicted\n",
        "\n",
        "model = LogisticRegression(n_features)"
      ],
      "metadata": {
        "id": "xc_CIf8Dbpo0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss Function and Optimizer\n"
      ],
      "metadata": {
        "id": "NlNrPxU2iejL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2) loss and optimizer\n",
        "learning_rate = 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "beZ4u1Yaipmi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w, b = model.parameters()"
      ],
      "metadata": {
        "id": "D0lP77K3jbY4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rFhuk3xje65",
        "outputId": "777d10b7-d6e4-46d3-9c4a-174f49d09b3a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-0.0043,  0.1369, -0.0485, -0.0528,  0.0683,  0.1412,  0.1063,  0.0006,\n",
              "          0.1716,  0.1273, -0.0572, -0.0027,  0.1664,  0.0651,  0.1590,  0.1653,\n",
              "          0.0289,  0.1070,  0.0254, -0.0226, -0.1584, -0.0718, -0.0638, -0.1323,\n",
              "          0.0438,  0.1572, -0.0098,  0.0239, -0.0869,  0.1671]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSqMK-WsjfmX",
        "outputId": "809060ad-e465-405a-f595-722317081215"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.1517], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop"
      ],
      "metadata": {
        "id": "LlebPSVfjst9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "    #forward pass and loss\n",
        "    y_predicted = model(X_train)\n",
        "    loss = criterion(y_predicted, y_train)\n",
        "\n",
        "    #backward pass:gradients\n",
        "    loss.backward()\n",
        "\n",
        "    #update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    #zero gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'epoch = {epoch+1}, loss = {loss.item():.4f}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOgHQXmUjjig",
        "outputId": "1edaee97-5475-4c59-f61d-c126cd7da466"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch = 10, loss = 0.7189\n",
            "epoch = 20, loss = 0.5533\n",
            "epoch = 30, loss = 0.4532\n",
            "epoch = 40, loss = 0.3887\n",
            "epoch = 50, loss = 0.3445\n",
            "epoch = 60, loss = 0.3124\n",
            "epoch = 70, loss = 0.2881\n",
            "epoch = 80, loss = 0.2689\n",
            "epoch = 90, loss = 0.2534\n",
            "epoch = 100, loss = 0.2405\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n"
      ],
      "metadata": {
        "id": "vAfB-_06lOU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluation should not be the part of computational graph so\n",
        "#for testing we don't need to track gradients\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_predicted = model(X_test)\n",
        "\n",
        "    #remember the sigmoid function will return a value between 0 and 1\n",
        "    #and if it's larger than 0.5 we say that this is class 1 otherwise 0\n",
        "    y_predicted_cls = y_predicted.round()\n",
        "\n",
        "    #accuray formula \n",
        "    #acc = no of correct predictions/ total no of predictions\n",
        "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
        "\n",
        "    #y_predicted_cls.eq(y_test).sum() this method will calculate no of correct predictions.\n",
        "\n",
        "    print(f'accuracy = {acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2okCscZOlN5j",
        "outputId": "2a30207d-1b97-4245-8009-21da8c4b1b1d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 0.9474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_predicted_cls.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIIcPaxcri6h",
        "outputId": "ef608d6a-c3ee-445a-cd83-1ba0680de37e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([114, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIMceYxyq8dn",
        "outputId": "630d819f-2a99-4f22-f76f-1df731dde330"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([114, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y_predicted_cls.eq(y_test)"
      ],
      "metadata": {
        "id": "gHihr6wOq2Et"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRc8R_r2rcJm",
        "outputId": "363fa989-a1f2-46bf-9578-7ec3171b4816"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([114, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yynJ3ZPvuBh6",
        "outputId": "65e0912d-18bf-4345-f93e-735f5e2f5d5e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.count_nonzero(z == True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9uv4si1r8nS",
        "outputId": "b1f0a3e0-1472-4a49-c4a8-e77f8e30bac0"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OLIgi3iVr_b8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}