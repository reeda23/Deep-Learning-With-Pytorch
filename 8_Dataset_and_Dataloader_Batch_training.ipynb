{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8.Dataset_and_Dataloader_Batch_training.ipynb",
      "provenance": [],
      "mount_file_id": "1TIRIIi9cOPanRFpTD58ls1l-YF0HgqAt",
      "authorship_tag": "ABX9TyMIUoGGaU54HmrYlZG/6RhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reeda23/Deep-Learning-With-Pytorch/blob/main/8_Dataset_and_Dataloader_Batch_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "data = numpy.loadtext('wine.csv')\n",
        " \n",
        " #training loop\n",
        "\n",
        " for epoch in range(1000): <br>\n",
        "     x,y = data <br>\n",
        "     forward + backward + weight updates <br>\n",
        "'''"
      ],
      "metadata": {
        "id": "2_hR1cLzC1MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The above setting might be very time consuming if we do gradient calculations on the whole training data so a better way for large data sets is to divide the samples into smaller batches and our tarining loop looks like this..."
      ],
      "metadata": {
        "id": "MNE5GQjTB1dl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-PMD-T0AsI6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#training loop\n",
        "\n",
        "for epoch in range(1000):\n",
        "    #loop over all batches\n",
        "    for i in range(total_batches):\n",
        "        x_batch, y_batch = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Epoch:** one forward and backward pass of ALL training samples <br>\n",
        "**batch_size:** number of training samples used in one forward/backward pass <br>\n",
        "**number of iterations:** number of passes, each pass(forward + backward) using [batch_size] no of samples <br>\n",
        "\n",
        "e.g: 100 trainning samples, batch-size = 20 -> 100/20 = 5 iterations for 1 epoch"
      ],
      "metadata": {
        "id": "5tetU70YDgZY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Libraries"
      ],
      "metadata": {
        "id": "mNysG9nkEt_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import math\n"
      ],
      "metadata": {
        "id": "kX5uQPRDExdX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Custom Dataset:\n"
      ],
      "metadata": {
        "id": "lpg4KJbCFZUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inherit Dataset<br>\n",
        "#Implement _init_, __getitem__, and __len__'\n",
        "\n",
        "class WineDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        #data loading\n",
        "        xy = np.loadtxt('/content/drive/MyDrive/Colab Notebooks/Deep_Learning_With_Pytorch/data/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
        "        self.x = torch.from_numpy(xy[:, 1:])\n",
        "        self.y = torch.from_numpy(xy[:,[0]]) #n_samples, 1 \n",
        "        self.n_samples = xy.shape[0]\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #dataset[0]\n",
        "        return self.x[index], self.y[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        #len(dataset)\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "9j01UMrwE_ut"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = WineDataset()\n",
        "first_data = dataset[0]\n",
        "features, labels = first_data\n",
        "print(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptT7flOjIv12",
        "outputId": "33042c66-7ddf-43a8-8e24-5ecc51a4fc76"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
            "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
            "        1.0650e+03]) tensor([1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "_WYhN5bSJdX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = DataLoader(dataset=dataset, batch_size= 4, shuffle= True, num_workers=2)\n",
        "\n",
        "#Num_workers tells the data loader instance how many sub-processes to use for data loading. \n",
        "#If the num_worker is zero (default) the GPU has to weight for CPU to load data. \n",
        "#Theoretically, greater the num_workers, more efficiently the CPU load data and less the GPU has to wait\n",
        "\n",
        "dataiter = iter(dataloader)\n",
        "data = dataiter.next()\n",
        "features, labels = data\n",
        "print(features, labels)\n",
        "\n",
        "#batch size = 4 that's why we see 4 different feature vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_a6LOMOxJOCt",
        "outputId": "72a08601-54ea-40a3-9231-2088158b08d8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2370e+01, 1.1700e+00, 1.9200e+00, 1.9600e+01, 7.8000e+01, 2.1100e+00,\n",
            "         2.0000e+00, 2.7000e-01, 1.0400e+00, 4.6800e+00, 1.1200e+00, 3.4800e+00,\n",
            "         5.1000e+02],\n",
            "        [1.3480e+01, 1.8100e+00, 2.4100e+00, 2.0500e+01, 1.0000e+02, 2.7000e+00,\n",
            "         2.9800e+00, 2.6000e-01, 1.8600e+00, 5.1000e+00, 1.0400e+00, 3.4700e+00,\n",
            "         9.2000e+02],\n",
            "        [1.2450e+01, 3.0300e+00, 2.6400e+00, 2.7000e+01, 9.7000e+01, 1.9000e+00,\n",
            "         5.8000e-01, 6.3000e-01, 1.1400e+00, 7.5000e+00, 6.7000e-01, 1.7300e+00,\n",
            "         8.8000e+02],\n",
            "        [1.4300e+01, 1.9200e+00, 2.7200e+00, 2.0000e+01, 1.2000e+02, 2.8000e+00,\n",
            "         3.1400e+00, 3.3000e-01, 1.9700e+00, 6.2000e+00, 1.0700e+00, 2.6500e+00,\n",
            "         1.2800e+03]]) tensor([[2.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we can also iterate over whole data loader\n",
        "dataloader = DataLoader(dataset=dataset, batch_size= 4, shuffle= True, num_workers=2)\n",
        "\n",
        "#training loop\n",
        "num_epochs = 2 \n",
        "total_samples = len(dataset)\n",
        "n_iterations = math.ceil(total_samples/ 4) #4 is batch size\n",
        "print(total_samples, n_iterations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0AZLOSvKsFM",
        "outputId": "7e68268c-7a51-4353-bbe0-39cac1c04b5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "178 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "Zr7dxFpdMAnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    for i, (inputs, labels) in enumerate(dataloader): #enumerate func will give us index\n",
        "        #forward, backward, update \n",
        "        if (i+1)% 5 == 0:\n",
        "            print(f'epoch: {epoch+1}/{num_epochs}, Iterations: {i+1}/{n_iterations}, inputs: {inputs.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsZeGrofMJGF",
        "outputId": "920cb653-3448-44a7-b6b9-3e77879ddb61"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1/2, Iterations: 5/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 10/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 15/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 20/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 25/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 30/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 35/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 40/45, inputs: torch.Size([4, 13])\n",
            "epoch: 1/2, Iterations: 45/45, inputs: torch.Size([2, 13])\n",
            "epoch: 2/2, Iterations: 5/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 10/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 15/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 20/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 25/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 30/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 35/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 40/45, inputs: torch.Size([4, 13])\n",
            "epoch: 2/2, Iterations: 45/45, inputs: torch.Size([2, 13])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torchvision.datasets.MNIST()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "UHBExz8ONvJ0",
        "outputId": "58af76ba-d9a2-4205-81ea-a0feccdf4d2d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ede3c855859c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'root'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TrpmB69eNzmw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}